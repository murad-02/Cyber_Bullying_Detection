<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>About - Cyberbullying Detection System</title>
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            color: #333;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
        }

        .header {
            text-align: center;
            margin-bottom: 40px;
            color: white;
        }

        .header h1 {
            font-size: 3rem;
            margin-bottom: 10px;
            text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
        }

        .header p {
            font-size: 1.2rem;
            opacity: 0.9;
        }

        .back-btn {
            position: absolute;
            top: 20px;
            left: 20px;
            background: rgba(255, 255, 255, 0.2);
            color: white;
            padding: 10px 20px;
            border-radius: 25px;
            text-decoration: none;
            backdrop-filter: blur(10px);
            transition: all 0.3s ease;
        }

        .back-btn:hover {
            background: rgba(255, 255, 255, 0.3);
            transform: translateY(-2px);
        }

        .content-section {
            background: white;
            border-radius: 20px;
            padding: 40px;
            margin-bottom: 30px;
            box-shadow: 0 20px 40px rgba(0,0,0,0.1);
        }

        .section-title {
            color: #4a5568;
            margin-bottom: 20px;
            font-size: 2rem;
            display: flex;
            align-items: center;
            gap: 15px;
        }

        .section-content {
            line-height: 1.8;
            color: #666;
            font-size: 1.1rem;
        }

        .model-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 20px;
            margin-top: 30px;
        }

        .model-card {
            background: #f8fafc;
            padding: 25px;
            border-radius: 15px;
            border-left: 5px solid #667eea;
        }

        .model-title {
            font-size: 1.3rem;
            font-weight: 600;
            color: #4a5568;
            margin-bottom: 10px;
            display: flex;
            align-items: center;
            gap: 10px;
        }

        .model-description {
            color: #666;
            line-height: 1.6;
        }

        .stats-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 20px;
            margin-top: 30px;
        }

        .stat-card {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 25px;
            border-radius: 15px;
            text-align: center;
        }

        .stat-number {
            font-size: 2.5rem;
            font-weight: 700;
            margin-bottom: 10px;
        }

        .stat-label {
            font-size: 1.1rem;
            opacity: 0.9;
        }

        .class-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 15px;
            margin-top: 20px;
        }

        .class-card {
            background: #f8fafc;
            padding: 20px;
            border-radius: 10px;
            border-left: 4px solid #667eea;
        }

        .class-name {
            font-weight: 600;
            color: #4a5568;
            margin-bottom: 8px;
        }

        .class-description {
            color: #666;
            font-size: 0.95rem;
        }

        .tech-stack {
            display: flex;
            flex-wrap: wrap;
            gap: 10px;
            margin-top: 20px;
        }

        .tech-tag {
            background: #e2e8f0;
            color: #4a5568;
            padding: 8px 15px;
            border-radius: 20px;
            font-size: 0.9rem;
            font-weight: 500;
        }

        @media (max-width: 768px) {
            .header h1 {
                font-size: 2rem;
            }
            
            .content-section {
                padding: 20px;
            }
            
            .model-grid, .stats-grid {
                grid-template-columns: 1fr;
            }
        }
    </style>
</head>
<body>
    <a href="/" class="back-btn">
        <i class="fas fa-arrow-left"></i> Back to Home
    </a>

    <div class="container">
        <div class="header">
            <h1><i class="fas fa-info-circle"></i> About the System</h1>
            <p>Learn about our advanced cyberbullying detection technology</p>
        </div>

        <div class="content-section">
            <h2 class="section-title">
                <i class="fas fa-shield-alt"></i>
                What is Cyberbullying Detection?
            </h2>
            <div class="section-content">
                <p>
                    Our Cyberbullying Detection System is an advanced AI-powered solution designed to identify and classify 
                    various types of harmful content in online communications. Using state-of-the-art machine learning 
                    techniques, the system can detect cyberbullying content in multiple languages, including Bangla and English.
                </p>
                <p>
                    The system analyzes text content and categorizes it into different types of cyberbullying, helping 
                    platforms, educators, and parents identify potentially harmful content and take appropriate action.
                </p>
            </div>
        </div>

        <div class="content-section">
            <h2 class="section-title">
                <i class="fas fa-brain"></i>
                How It Works
            </h2>
            <div class="section-content">
                <p>
                    Our system uses an ensemble approach that combines three different machine learning models to achieve 
                    maximum accuracy and reliability:
                </p>
                
                <div class="model-grid">
                    <div class="model-card">
                        <div class="model-title">
                            <i class="fas fa-language"></i>
                            BERT Model
                        </div>
                        <div class="model-description">
                            Uses the BERT (Bidirectional Encoder Representations from Transformers) architecture, 
                            specifically fine-tuned for multilingual text classification. This model excels at 
                            understanding context and nuances in language.
                        </div>
                    </div>
                    
                    <div class="model-card">
                        <div class="model-title">
                            <i class="fas fa-network-wired"></i>
                            LSTM Model
                        </div>
                        <div class="model-description">
                            Long Short-Term Memory neural network that processes text sequentially, capturing 
                            temporal dependencies and patterns in the text that might indicate cyberbullying behavior.
                        </div>
                    </div>
                    
                    <div class="model-card">
                        <div class="model-title">
                            <i class="fas fa-tree"></i>
                            Random Forest
                        </div>
                        <div class="model-description">
                            Traditional machine learning approach using TF-IDF features to identify patterns 
                            in word usage and frequency that are characteristic of cyberbullying content.
                        </div>
                    </div>
                </div>
                
                <p style="margin-top: 20px;">
                    The ensemble combines predictions from all three models using a meta-classifier (Logistic Regression) 
                    to make the final decision, resulting in higher accuracy than any single model alone.
                </p>
            </div>
        </div>

        <div class="content-section">
            <h2 class="section-title">
                <i class="fas fa-chart-bar"></i>
                Performance Statistics
            </h2>
            <div class="stats-grid">
                <div class="stat-card">
                    <div class="stat-number">88.5%</div>
                    <div class="stat-label">Overall Accuracy</div>
                </div>
                <div class="stat-card">
                    <div class="stat-number">5</div>
                    <div class="stat-label">Cyberbullying Categories</div>
                </div>
                <div class="stat-card">
                    <div class="stat-number">2+</div>
                    <div class="stat-label">Languages Supported</div>
                </div>
                <div class="stat-card">
                    <div class="stat-number">6600+</div>
                    <div class="stat-label">Training Samples</div>
                </div>
            </div>
        </div>

        <div class="content-section">
            <h2 class="section-title">
                <i class="fas fa-tags"></i>
                Cyberbullying Categories
            </h2>
            <div class="section-content">
                <p>
                    Our system can detect and classify content into the following categories:
                </p>
                
                <div class="class-grid">
                    <div class="class-card">
                        <div class="class-name">Not Bully</div>
                        <div class="class-description">
                            Normal, non-harmful content that doesn't contain any form of cyberbullying.
                        </div>
                    </div>
                    
                    <div class="class-card">
                        <div class="class-name">Religious</div>
                        <div class="class-description">
                            Content that targets individuals or groups based on their religious beliefs or practices.
                        </div>
                    </div>
                    
                    <div class="class-card">
                        <div class="class-name">Sexual</div>
                        <div class="class-description">
                            Sexually explicit or inappropriate content that constitutes harassment or bullying.
                        </div>
                    </div>
                    
                    <div class="class-card">
                        <div class="class-name">Threat</div>
                        <div class="class-description">
                            Content that contains threats of violence, harm, or other forms of intimidation.
                        </div>
                    </div>
                    
                    <div class="class-card">
                        <div class="class-name">Troll</div>
                        <div class="class-description">
                            Deliberately provocative or inflammatory content designed to upset or anger others.
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <div class="content-section">
            <h2 class="section-title">
                <i class="fas fa-cogs"></i>
                Technology Stack
            </h2>
            <div class="section-content">
                <p>
                    Our system is built using cutting-edge technologies and frameworks:
                </p>
                
                <div class="tech-stack">
                    <span class="tech-tag">Python</span>
                    <span class="tech-tag">PyTorch</span>
                    <span class="tech-tag">Transformers</span>
                    <span class="tech-tag">BERT</span>
                    <span class="tech-tag">LSTM</span>
                    <span class="tech-tag">Scikit-learn</span>
                    <span class="tech-tag">Flask</span>
                    <span class="tech-tag">HTML/CSS</span>
                    <span class="tech-tag">JavaScript</span>
                    <span class="tech-tag">TensorFlow</span>
                    <span class="tech-tag">NLTK</span>
                    <span class="tech-tag">Pandas</span>
                    <span class="tech-tag">NumPy</span>
                </div>
            </div>
        </div>

        <div class="content-section">
            <h2 class="section-title">
                <i class="fas fa-lightbulb"></i>
                Use Cases
            </h2>
            <div class="section-content">
                <p>
                    This cyberbullying detection system can be used in various contexts:
                </p>
                <ul style="margin-left: 20px; margin-top: 15px;">
                    <li><strong>Social Media Platforms:</strong> Automatically flag potentially harmful content for review</li>
                    <li><strong>Educational Institutions:</strong> Monitor student communications and online activities</li>
                    <li><strong>Parental Control:</strong> Help parents identify cyberbullying in their children's online interactions</li>
                    <li><strong>Content Moderation:</strong> Assist human moderators in identifying problematic content</li>
                    <li><strong>Research:</strong> Study patterns and trends in online harassment</li>
                    <li><strong>Mental Health Support:</strong> Early detection of cyberbullying to provide timely intervention</li>
                </ul>
            </div>
        </div>

        <div class="content-section">
            <h2 class="section-title">
                <i class="fas fa-exclamation-triangle"></i>
                Important Note
            </h2>
            <div class="section-content">
                <p>
                    While our system achieves high accuracy, it should be used as a tool to assist human judgment, 
                    not as a replacement for human oversight. The final decision about content moderation should 
                    always involve human review, especially in sensitive cases.
                </p>
                <p>
                    The system is designed to reduce false positives and provide reliable detection, but no 
                    automated system is perfect. Regular updates and improvements are made based on new data 
                    and feedback to maintain high performance standards.
                </p>
            </div>
        </div>
    </div>
</body>
</html>
